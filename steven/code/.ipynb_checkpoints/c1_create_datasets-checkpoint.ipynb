{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Competition\n",
    "# iMaterialist Challenge: Furniture\n",
    "### Data Processing\n",
    "#### Team: LSDA-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/steven/.local/share/virtualenvs/B4-5100-4F18-LSDA-iftAmOns/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import json\n",
    "import csv\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import h5py\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "from os.path import abspath, isfile, join, basename\n",
    "from time import sleep\n",
    "import re\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving the Data from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../json/train.json') as datafile1:\n",
    "    data1 = json.load(datafile1)\n",
    "\n",
    "with open('../../json/test.json') as datafile2:\n",
    "    data2 = json.load(datafile2)\n",
    "\n",
    "with open(\"../../json/validation.json\") as datafile3:\n",
    "    data3 = json.load(datafile3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting JSON format data into Tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training   = json.load(open('../../json/train.json'))\n",
    "test       = json.load(open('../../json/test.json'))\n",
    "validation = json.load(open('../../json/validation.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinFn(dat):\n",
    "    return [dat[0][\"url\"][0], dat[0][\"image_id\"], dat[1][\"label_id\"]]\n",
    "\n",
    "train_data      = pd.DataFrame(list(map(joinFn,zip(training[\"images\"],training[\"annotations\"]))),\\\n",
    "                               columns=['url','image_id','label_id'])\n",
    "test_data       = pd.DataFrame(list(map(lambda x: x[\"url\"],test[\"images\"])),columns=[\"url\"])\n",
    "validation_data = pd.DataFrame(list(map(joinFn, zip(validation[\"images\"],validation[\"annotations\"]))),\\\n",
    "                               columns=['url','image_id','label_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>image_id</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://img13.360buyimg.com/imgzone/jfs/t2857/...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.tengdakeli.cn/350/timg01/uploaded/i...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://img13.360buyimg.com/imgzone/jfs/t8899/...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://img4.tbcdn.cn/tfscom/i1/2855447419/TB2S...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://a.vpimg4.com/upload/merchandise/287883/...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  image_id  label_id\n",
       "0  https://img13.360buyimg.com/imgzone/jfs/t2857/...         1         5\n",
       "1  http://www.tengdakeli.cn/350/timg01/uploaded/i...         2         5\n",
       "2  https://img13.360buyimg.com/imgzone/jfs/t8899/...         3         5\n",
       "3  http://img4.tbcdn.cn/tfscom/i1/2855447419/TB2S...         4         5\n",
       "4  http://a.vpimg4.com/upload/merchandise/287883/...         5         5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Rows for which no images are downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_list(directory):\n",
    "    directory = abspath(directory)\n",
    "    filenames  = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "    files = [Path(directory + '/' + f) for f in natsorted(filenames)]\n",
    "\n",
    "    return(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_train = file_list('../images/train/')\n",
    "ids_train = [int(re.match('\\d+', basename(f)).group(0))-1 for f in files_train]\n",
    "\n",
    "files_test = file_list('../images/test/')\n",
    "ids_test = [int(re.match('\\d+', basename(f)).group(0))-1 for f in files_test]\n",
    "\n",
    "files_val = file_list('../images/validation/')\n",
    "ids_val = [int(re.match('\\d+', basename(f)).group(0))-1 for f in files_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(train_data.index[[ids_train]])\n",
    "test_data.drop(test_data.index[[ids_test]])\n",
    "validation_data.drop(validation_data.index[[ids_val]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Read Images as NP arays and save as HDF5 sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resize_image(infilename, size, bw=True):\n",
    "    if bw:\n",
    "        img = Image.open(infilename).convert('L')\n",
    "    else:\n",
    "        img = Image.open(infilename)\n",
    "    img.load()\n",
    "    img = img.resize((size, size), resample=Image.LANCZOS)\n",
    "    data = np.asarray(img, dtype=\"int32\" )\n",
    "    return data\n",
    "\n",
    "\n",
    "def list_images_labels(X, y, size=256, bw=True):\n",
    "    datalen = range(len(X))\n",
    "\n",
    "    images = [load_resize_image(X[i], size, bw) for i in tqdm(datalen)]\n",
    "    labels = [y[i] for i in datalen]\n",
    "    \n",
    "    return(images,labels)\n",
    "\n",
    "\n",
    "def save_file(set,X,y,id):\n",
    "    '''\n",
    "        set in {\"train\",\"test\"}\n",
    "        id = file number\n",
    "        X = train_images...\n",
    "        y = train_labels...\n",
    "    '''\n",
    "    with h5py.File('{}_{}.h5'.format(set,id), 'w') as hf:\n",
    "        group = hf.create_group(set)\n",
    "        group.create_dataset('images', data=X)\n",
    "        group.create_dataset('labels', data=y)\n",
    "        \n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    # https://stackoverflow.com/a/312464\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Train\n",
      "Reading Test\n",
      "Reading Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/192171 [00:00<1:36:24, 33.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating and saving Datasets\n",
      "Train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 400/192171 [00:09<1:19:29, 40.21it/s]/Users/steven/.local/share/virtualenvs/B4-5100-4F18-LSDA-iftAmOns/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 75%|███████▍  | 143670/192171 [1:08:06<22:59, 35.16it/s]"
     ]
    }
   ],
   "source": [
    "img_size = 28\n",
    "color_bw = True\n",
    "\n",
    "print('Reading Train')\n",
    "labels_train = train_data['label_id'].tolist()\n",
    "\n",
    "print('Reading Test')\n",
    "labels_test = [-1] * len(files_test)\n",
    "\n",
    "print('Reading Validation')\n",
    "labels_val = validation_data['label_id'].tolist()\n",
    "\n",
    "\n",
    "sleep(2)\n",
    "print('Generating and saving Datasets')\n",
    "print('Train:')\n",
    "\n",
    "# train_chunks = list(chunks(range(len(files_train)), round(len(files_train)/10)))\n",
    "# for i, chunk in enumerate(train_chunks):\n",
    "#     start = train_chunks[0][0]\n",
    "#     end = train_chunks[0][-1]\n",
    "#     im_train = list_images_labels(files_train[start:end], labels_train[start:end], img_size)\n",
    "#     save_file('train', im_train[0], im_train[1], i)\n",
    "#     print('{} of {} done...'.format(i+1, len(train_chunks)-1))\n",
    "\n",
    "im_train = list_images_labels(files_train, labels_train, img_size, bw=color_bw)\n",
    "save_file('train', im_train[0], im_train[1], 'train')\n",
    "\n",
    "\n",
    "# print('Test:')\n",
    "# im_test = list_images_labels(files_test, labels_test, img_size, bw=color_bw)\n",
    "# save_file('test', im_test[0], labels_test, 'test')\n",
    "\n",
    "\n",
    "# print('Validation:')\n",
    "# im_val = list_images_labels(files_val, labels_val, img_size, bw=color_bw)\n",
    "# save_file('validation', im_val[0], im_val[1], 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check HDF5 sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combining hdf5 files\n",
    "If a datasets is split across multiple .hd5 files, they can be accessed via interlinking them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = h5py.File('../images/img32/train_0.h5','w')\n",
    "data_train['train1'] = h5py.ExternalLink('train_1.h5', '../images/img32/')\n",
    "data_train['train2'] = h5py.ExternalLink('train_2.h5', '../images/img32/')\n",
    "data_train['train3'] = h5py.ExternalLink('train_3.h5', '../images/img32/')\n",
    "data_train['train4'] = h5py.ExternalLink('train_4.h5', '../images/img32/')\n",
    "data_train['train5'] = h5py.ExternalLink('train_5.h5', '../images/img32/')\n",
    "data_train['train6'] = h5py.ExternalLink('train_6.h5', '../images/img32/')\n",
    "data_train['train7'] = h5py.ExternalLink('train_7.h5', '../images/img32/')\n",
    "data_train['train8'] = h5py.ExternalLink('train_8.h5', '../images/img32/')\n",
    "data_train['train9'] = h5py.ExternalLink('train_9.h5', '../images/img32/')\n",
    "data_train['train10'] = h5py.ExternalLink('train_10.h5', '../images/img32/')\n",
    "# how to get it all as one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = h5py.File('../images/img28/train_28.h5', 'r')\n",
    "d_test = h5py.File('../images/img28/test_28.h5', 'r')\n",
    "d_val = h5py.File('../images/img28/validation_28.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = d_train['train']['images']\n",
    "ytrain = d_train['train']['labels']\n",
    "\n",
    "Xtest = d_test['test']['images']\n",
    "\n",
    "Xval = d_val['validation']['images']\n",
    "yval = d_val['validation']['labels']\n",
    "\n",
    "print(\\\n",
    "'Training samples: {}\\n\\\n",
    "Test samples: {}\\n\\\n",
    "Validation Samples: {}'.format(Xtrain.shape[0], Xtest.shape[0], Xval.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ending with a Image from the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first image \n",
    "i1 = Xval[0]\n",
    "# i1_plot = plt.imshow(i1)\n",
    "i1_plot = plt.imshow(i1, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
